{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff19f495-59af-474f-a381-d7d78ad4a570",
   "metadata": {},
   "source": [
    "\n",
    "# NaviGator Toolkit API test\n",
    "\n",
    "This notebook is designed to test connection to the NaviGator Toolkit API ([see here for more information](https://it.ufl.edu/ai/navigator-toolkit/)). You will need a NaviGator API key. The key should be stored in a `.json` file with the following format:\n",
    "\n",
    "    {\n",
    "      \"OPENAI_API_KEY\" : \"Put your key here in the quotes\",\n",
    "      \"base_url\" : \"https://api.ai.it.ufl.edu/\"\n",
    "    }\n",
    "\n",
    "We suggest putting that in your home directory, to minimize the chances of accidentally adding and committing the file to a git repo. Remember that anyone with your API key can use NaviGator as you! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ba376d4-d4f1-4e48-a7c0-3ca4a7c144c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0742a36-ccf5-4d0c-9c71-f2ba7b7735cb",
   "metadata": {},
   "source": [
    "## Load `.json` file with your key and api endpoint URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1742595-a563-4065-be5a-2b08107bdbe1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the path to your jsnkey file\n",
    "key_file = '/home/magitz/navigator_api_keys.json'\n",
    "\n",
    "\n",
    "# Load the JSON file\n",
    "with open(key_file, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract the values\n",
    "OPENAI_API_KEY = data.get('OPENAI_API_KEY')\n",
    "base_url = data.get('base_url')\n",
    "\n",
    "# Set the environment variable\n",
    "os.environ['TOOLKIT_API_KEY'] = OPENAI_API_KEY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05900196-4d7d-4dea-8b6a-9c119bfd3035",
   "metadata": {},
   "source": [
    "## Test connectivity and get model list\n",
    "\n",
    "Reply should list the models that are available with your API key. An example, truncated, output is:\n",
    "\n",
    "    SyncPage[Model](data=[Model(id='llama-3.1-70b-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='sfr-embedding-mistral', created=1677610602, object='model', owned_by='openai'),...)], object='list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ea3baa5-eea7-46f3-aa91-753907b44ad7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncPage[Model](data=[Model(id='codestral-22b', created=1677610602, object='model', owned_by='openai'), Model(id='whisper-large-v3', created=1677610602, object='model', owned_by='openai'), Model(id='mistral-7b-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='mixtral-8x7b-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='gte-large-en-v1.5', created=1677610602, object='model', owned_by='openai'), Model(id='llama-3.1-8b-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='llama-3.1-70b-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='flux.1-dev', created=1677610602, object='model', owned_by='openai'), Model(id='flux.1-schnell', created=1677610602, object='model', owned_by='openai'), Model(id='sfr-embedding-mistral', created=1677610602, object='model', owned_by='openai'), Model(id='nomic-embed-text-v1.5', created=1677610602, object='model', owned_by='openai')], object='list')\n"
     ]
    }
   ],
   "source": [
    "# Check list of available models\n",
    "client = openai.OpenAI(\n",
    "    api_key=os.environ.get(\"TOOLKIT_API_KEY\"),\n",
    "    base_url=base_url\n",
    ")\n",
    "\n",
    "response = client.models.list()\n",
    " \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f4cac6-0d83-4a2d-ae59-97c7dfba8a6e",
   "metadata": {},
   "source": [
    "## Test model completion\n",
    "\n",
    "You may need to update the model from the list above as the available models change over time.\n",
    "\n",
    "Here is an example response. Remember that LLM generation is stochastic, so you should not expect to get the same reply, but something similar.\n",
    "   \n",
    "       ChatCompletion(id='chat-644e583f079c4c33a1e95480caca4f99', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Here's a short poem about ice cream:\\n\\nA cone in my hand, oh so sweet,\\nA treat that can't be beat.\\nThe flavors dance on my tongue so bright,\\nA delightful treat on a summer night.\\n\\nThe colors and sprinkles, a joyful sight,\\nA smile on my face, pure delight.\\nThe cold and creamy texture, a pleasure to share,\\nA sweet indulgence, beyond compare.\\n\\nSo here's to ice cream, a treat so fine,\\nA sweet escape, that's simply divine.\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1739560733, model='meta-llama/Llama-3.1-70B-Instruct', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=104, prompt_tokens=45, total_tokens=149, completion_tokens_details=None, prompt_tokens_details=None), prompt_logprobs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc1c6dca-b4ed-4529-ae65-4f475fd18f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chat-e6729fbe77574b1f91d56fb6788355dc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Laughter echoes through the air,\\nA Ferris wheel spins with flair,\\nChildren's smiles, a joyful sight,\\nA summer night, pure delight.\\n\\nThe scent of sugar wafts so sweet,\\nCotton candy treats to eat,\\nThe sound of games, a lively beat,\\nA carnival, where hearts skip a treat.\\n\\nThe stars shine bright, a twinkling show,\\nA night of fun, for all to know,\\n Memories made, with love and glee,\\nA magical night, for you and me.\", role='assistant', function_call=None, tool_calls=None, refusal=None))], created=1740579138, model='meta-llama/Llama-3.1-70B-Instruct', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=103, prompt_tokens=45, total_tokens=148, completion_tokens_details=None, prompt_tokens_details=None), service_tier=None, prompt_logprobs=None)\n"
     ]
    }
   ],
   "source": [
    "# Set model from list above\n",
    "model = \"llama-3.1-70b-instruct\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write a short poem about somethign fun.\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    " \n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e759c8e-9de9-454a-b796-1d5240139d13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laughter echoes through the air,\n",
      "A Ferris wheel spins with flair,\n",
      "Children's smiles, a joyful sight,\n",
      "A summer night, pure delight.\n",
      "\n",
      "The scent of sugar wafts so sweet,\n",
      "Cotton candy treats to eat,\n",
      "The sound of games, a lively beat,\n",
      "A carnival, where hearts skip a treat.\n",
      "\n",
      "The stars shine bright, a twinkling show,\n",
      "A night of fun, for all to know,\n",
      " Memories made, with love and glee,\n",
      "A magical night, for you and me.\n"
     ]
    }
   ],
   "source": [
    "# Print nicely formatted message\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5992cae-bcac-4389-8358-71dfa1dd6a04",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test seding a system prompt and cotent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da15e2db-2641-4982-aa55-94f9300ef73c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chat-4b55133175fe485488d3381415b9d62c', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\" In the grand cosmic theatre, where stars are the actors, the largest galaxy takes center stage. This celestial titan, known as IC 1101, stretches across 5.5 million light-years, a distance so vast, it's as if it's reaching out to touch the very edges of infinity.\\n\\nImagine a tapestry woven with countless stars, each a twinkling thread of light, intertwined with nebulas, galaxies, and cosmic dust. This tapestry, woven over eons, is IC 1101. It's a testament to the relentless dance of celestial bodies, a symphony of creation and destruction, all set against the backdrop of an unfathomable void.\\n\\nYet, the universe is a dynamic, ever-evolving place. Even this colossal galaxy is not static. It's a swirling, spiraling dance of stars, each with its own story to tell, each a fragment of time frozen, a moment etched in the fabric of the cosmos.\\n\\nSo, when you gaze upon the night sky, remember, you're looking at fragments of IC 1101, a glimpse into the vastness of the universe, a reminder of the intricate, complex tapestry that is our cosmic home. And perhaps, in that moment, you too might find yourself awestruck by the grandeur of the largest galaxy.\", role='assistant', function_call=None, tool_calls=None, refusal=None))], created=1740579141, model='mistralai/Mistral-7B-Instruct-v0.3', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=319, prompt_tokens=29, total_tokens=348, completion_tokens_details=None, prompt_tokens_details=None), service_tier=None, prompt_logprobs=None)\n"
     ]
    }
   ],
   "source": [
    "# Set model from list above\n",
    "model = 'mistral-7b-instruct'\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model, # model to send to the proxy\n",
    "    messages = [\n",
    "       {\n",
    "         \"role\": \"system\",\n",
    "         \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"\n",
    "      },\n",
    "       {\n",
    "         \"role\": \"user\",\n",
    "         \"content\": \"what is the largest galaxy?\"\n",
    "       }\n",
    "     ]\n",
    "\n",
    ")\n",
    " \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce369b19-2af3-4f85-a402-406330349fbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " In the grand cosmic theatre, where stars are the actors, the largest galaxy takes center stage. This celestial titan, known as IC 1101, stretches across 5.5 million light-years, a distance so vast, it's as if it's reaching out to touch the very edges of infinity.\n",
      "\n",
      "Imagine a tapestry woven with countless stars, each a twinkling thread of light, intertwined with nebulas, galaxies, and cosmic dust. This tapestry, woven over eons, is IC 1101. It's a testament to the relentless dance of celestial bodies, a symphony of creation and destruction, all set against the backdrop of an unfathomable void.\n",
      "\n",
      "Yet, the universe is a dynamic, ever-evolving place. Even this colossal galaxy is not static. It's a swirling, spiraling dance of stars, each with its own story to tell, each a fragment of time frozen, a moment etched in the fabric of the cosmos.\n",
      "\n",
      "So, when you gaze upon the night sky, remember, you're looking at fragments of IC 1101, a glimpse into the vastness of the universe, a reminder of the intricate, complex tapestry that is our cosmic home. And perhaps, in that moment, you too might find yourself awestruck by the grandeur of the largest galaxy.\n"
     ]
    }
   ],
   "source": [
    "# Print nicely formatted message\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7fa920-4a14-4c73-90ed-c395da6f57f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-1.3",
   "language": "python",
   "name": "nlp-1.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
