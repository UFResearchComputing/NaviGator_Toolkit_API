{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff19f495-59af-474f-a381-d7d78ad4a570",
   "metadata": {},
   "source": [
    "\n",
    "# NaviGator Toolkit Whisper (Speech to text) Demo\n",
    "\n",
    "This notebook is designed to test connection to the NaviGator Toolkit API ([see here for more information](https://it.ufl.edu/ai/navigator-toolkit/)) and use the [Whisper model](https://github.com/openai/whisper) to do speech to text transcription. You will need a NaviGator API key. The key should be stored in a `.json` file with the following format:\n",
    "\n",
    "    {\n",
    "      \"OPENAI_API_KEY\" : \"Put your key here in the quotes\",\n",
    "      \"base_url\" : \"https://api.ai.it.ufl.edu/\"\n",
    "    }\n",
    "\n",
    "We suggest putting that in your home directory, to minimize the chances of accidentally adding and committing the file to a git repo. Remember that anyone with your API key can use NaviGator as you! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ba376d4-d4f1-4e48-a7c0-3ca4a7c144c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0742a36-ccf5-4d0c-9c71-f2ba7b7735cb",
   "metadata": {},
   "source": [
    "## Load `.json` file with your key and api endpoint URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1742595-a563-4065-be5a-2b08107bdbe1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the path to your jsnkey file\n",
    "key_file = '/home/magitz/navigator_api_keys.json'\n",
    "\n",
    "\n",
    "# Load the JSON file\n",
    "with open(key_file, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract the values\n",
    "OPENAI_API_KEY = data.get('OPENAI_API_KEY')\n",
    "base_url = data.get('base_url')\n",
    "\n",
    "# Set the environment variable\n",
    "os.environ['TOOLKIT_API_KEY'] = OPENAI_API_KEY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05900196-4d7d-4dea-8b6a-9c119bfd3035",
   "metadata": {},
   "source": [
    "## Test connectivity and get model list\n",
    "\n",
    "Reply should list the models that are available with your API key. An example, truncated, output is:\n",
    "\n",
    "    SyncPage[Model](data=[Model(id='llama-3.1-70b-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='sfr-embedding-mistral', created=1677610602, object='model', owned_by='openai'),...)], object='list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ea3baa5-eea7-46f3-aa91-753907b44ad7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncPage[Model](data=[Model(id='flux.1-schnell', created=1677610602, object='model', owned_by='openai'), Model(id='granite-3.1-8b-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='llama-3.1-8b-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='mixtral-8x7b-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='nim-mistral-7b-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='llama-3.1-70b-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='nomic-embed-text-v1.5', created=1677610602, object='model', owned_by='openai'), Model(id='gte-large-en-v1.5', created=1677610602, object='model', owned_by='openai'), Model(id='mistral-7b-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='whisper-large-v3', created=1677610602, object='model', owned_by='openai'), Model(id='codestral-22b', created=1677610602, object='model', owned_by='openai'), Model(id='nim-llama-3.1-8b-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='flux.1-dev', created=1677610602, object='model', owned_by='openai'), Model(id='llama-3.3-70b-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='sfr-embedding-mistral', created=1677610602, object='model', owned_by='openai')], object='list')\n"
     ]
    }
   ],
   "source": [
    "# Check list of available models\n",
    "client = openai.OpenAI(\n",
    "    api_key=os.environ.get(\"TOOLKIT_API_KEY\"),\n",
    "    base_url=base_url\n",
    ")\n",
    "\n",
    "response = client.models.list()\n",
    " \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5718c829-bc94-454c-bbe8-1743465430c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flux.1-schnell\n",
      "granite-3.1-8b-instruct\n",
      "llama-3.1-8b-instruct\n",
      "mixtral-8x7b-instruct\n",
      "nim-mistral-7b-instruct\n",
      "llama-3.1-70b-instruct\n",
      "nomic-embed-text-v1.5\n",
      "gte-large-en-v1.5\n",
      "mistral-7b-instruct\n",
      "whisper-large-v3\n",
      "codestral-22b\n",
      "nim-llama-3.1-8b-instruct\n",
      "flux.1-dev\n",
      "llama-3.3-70b-instruct\n",
      "sfr-embedding-mistral\n"
     ]
    }
   ],
   "source": [
    "# Print available models in better format\n",
    "for model in response:\n",
    "    print(model.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f4cac6-0d83-4a2d-ae59-97c7dfba8a6e",
   "metadata": {},
   "source": [
    "## Test model completion\n",
    "\n",
    "You may need to update the model from the list above as the available models change over time.\n",
    "\n",
    "Here is an example response from the recording at `data/test_recording.m4a`:\n",
    "   \n",
    "    Transcription(text=\"This is a test audio recording. I want to test an AI model's ability to accurately generate a transcript of the recording. Thank you for listening, and go Gators!\", language='en', task='transcribe', duration=12.736, words=None, segments=[{'id': 1, 'avg_logprob': -0.07349917508269611, 'compression_ratio': 1.296, 'end': 11.52, 'no_speech_prob': 0.0149383544921875, 'seek': 1273, 'start': 0.0, 'temperature': 0.0, 'text': \" This is a test audio recording. I want to test an AI model's ability to accurately generate a transcript of the recording. Thank you for listening, and go Gators!\", 'tokens': [50365, 639, 307, 257, 1500, 6278, 6613, 13, 286, 528, 281, 1500, 364, 7318, 2316, 311, 3485, 281, 20095, 8460, 257, 24444, 295, 264, 6613, 13, 1044, 291, 337, 4764, 11, 293, 352, 460, 3391, 0, 50941], 'words': None}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc1c6dca-b4ed-4529-ae65-4f475fd18f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription(text=\"This is a test audio recording. I want to test an AI model's ability to accurately generate a transcript of the recording. Thank you for listening, and go Gators!\", language='en', task='transcribe', duration=12.736, words=None, segments=[{'id': 1, 'avg_logprob': -0.07349917508269611, 'compression_ratio': 1.296, 'end': 11.52, 'no_speech_prob': 0.0149383544921875, 'seek': 1273, 'start': 0.0, 'temperature': 0.0, 'text': \" This is a test audio recording. I want to test an AI model's ability to accurately generate a transcript of the recording. Thank you for listening, and go Gators!\", 'tokens': [50365, 639, 307, 257, 1500, 6278, 6613, 13, 286, 528, 281, 1500, 364, 7318, 2316, 311, 3485, 281, 20095, 8460, 257, 24444, 295, 264, 6613, 13, 1044, 291, 337, 4764, 11, 293, 352, 460, 3391, 0, 50941], 'words': None}])\n"
     ]
    }
   ],
   "source": [
    "# Set model from list above\n",
    "model = \"whisper-large-v3\"\n",
    "\n",
    "audio_file= open(\"data/test_recording.m4a\", \"rb\")\n",
    "transcription = client.audio.transcriptions.create(\n",
    "      model=\"whisper-large-v3\", \n",
    "      file=audio_file\n",
    "  )\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e759c8e-9de9-454a-b796-1d5240139d13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription(text=\"This is a test audio recording. I want to test an AI model's ability to accurately generate a transcript of the recording. Thank you for listening, and go Gators!\", language='en', task='transcribe', duration=12.736, words=None, segments=[{'id': 1, 'avg_logprob': -0.07349917508269611, 'compression_ratio': 1.296, 'end': 11.52, 'no_speech_prob': 0.0149383544921875, 'seek': 1273, 'start': 0.0, 'temperature': 0.0, 'text': \" This is a test audio recording. I want to test an AI model's ability to accurately generate a transcript of the recording. Thank you for listening, and go Gators!\", 'tokens': [50365, 639, 307, 257, 1500, 6278, 6613, 13, 286, 528, 281, 1500, 364, 7318, 2316, 311, 3485, 281, 20095, 8460, 257, 24444, 295, 264, 6613, 13, 1044, 291, 337, 4764, 11, 293, 352, 460, 3391, 0, 50941], 'words': None}])\n"
     ]
    }
   ],
   "source": [
    "# Print nicely formatted message\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5992cae-bcac-4389-8358-71dfa1dd6a04",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test seding a system prompt and cotent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da15e2db-2641-4982-aa55-94f9300ef73c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chat-4b55133175fe485488d3381415b9d62c', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\" In the grand cosmic theatre, where stars are the actors, the largest galaxy takes center stage. This celestial titan, known as IC 1101, stretches across 5.5 million light-years, a distance so vast, it's as if it's reaching out to touch the very edges of infinity.\\n\\nImagine a tapestry woven with countless stars, each a twinkling thread of light, intertwined with nebulas, galaxies, and cosmic dust. This tapestry, woven over eons, is IC 1101. It's a testament to the relentless dance of celestial bodies, a symphony of creation and destruction, all set against the backdrop of an unfathomable void.\\n\\nYet, the universe is a dynamic, ever-evolving place. Even this colossal galaxy is not static. It's a swirling, spiraling dance of stars, each with its own story to tell, each a fragment of time frozen, a moment etched in the fabric of the cosmos.\\n\\nSo, when you gaze upon the night sky, remember, you're looking at fragments of IC 1101, a glimpse into the vastness of the universe, a reminder of the intricate, complex tapestry that is our cosmic home. And perhaps, in that moment, you too might find yourself awestruck by the grandeur of the largest galaxy.\", role='assistant', function_call=None, tool_calls=None, refusal=None))], created=1740579141, model='mistralai/Mistral-7B-Instruct-v0.3', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=319, prompt_tokens=29, total_tokens=348, completion_tokens_details=None, prompt_tokens_details=None), service_tier=None, prompt_logprobs=None)\n"
     ]
    }
   ],
   "source": [
    "# Set model from list above\n",
    "model = 'mistral-7b-instruct'\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model, # model to send to the proxy\n",
    "    messages = [\n",
    "       {\n",
    "         \"role\": \"system\",\n",
    "         \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"\n",
    "      },\n",
    "       {\n",
    "         \"role\": \"user\",\n",
    "         \"content\": \"what is the largest galaxy?\"\n",
    "       }\n",
    "     ]\n",
    "\n",
    ")\n",
    " \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce369b19-2af3-4f85-a402-406330349fbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " In the grand cosmic theatre, where stars are the actors, the largest galaxy takes center stage. This celestial titan, known as IC 1101, stretches across 5.5 million light-years, a distance so vast, it's as if it's reaching out to touch the very edges of infinity.\n",
      "\n",
      "Imagine a tapestry woven with countless stars, each a twinkling thread of light, intertwined with nebulas, galaxies, and cosmic dust. This tapestry, woven over eons, is IC 1101. It's a testament to the relentless dance of celestial bodies, a symphony of creation and destruction, all set against the backdrop of an unfathomable void.\n",
      "\n",
      "Yet, the universe is a dynamic, ever-evolving place. Even this colossal galaxy is not static. It's a swirling, spiraling dance of stars, each with its own story to tell, each a fragment of time frozen, a moment etched in the fabric of the cosmos.\n",
      "\n",
      "So, when you gaze upon the night sky, remember, you're looking at fragments of IC 1101, a glimpse into the vastness of the universe, a reminder of the intricate, complex tapestry that is our cosmic home. And perhaps, in that moment, you too might find yourself awestruck by the grandeur of the largest galaxy.\n"
     ]
    }
   ],
   "source": [
    "# Print nicely formatted message\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7fa920-4a14-4c73-90ed-c395da6f57f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-1.3",
   "language": "python",
   "name": "nlp-1.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
