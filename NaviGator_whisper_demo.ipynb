{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff19f495-59af-474f-a381-d7d78ad4a570",
   "metadata": {},
   "source": [
    "\n",
    "# NaviGator Toolkit Whisper (Speech to text) Demo\n",
    "\n",
    "This notebook is designed to test connection to the NaviGator Toolkit API ([see here for more information](https://it.ufl.edu/ai/navigator-toolkit/)) and use the [Whisper model](https://github.com/openai/whisper) to do speech to text transcription. You will need a NaviGator API key. The key should be stored in a `.json` file with the following format:\n",
    "\n",
    "    {\n",
    "      \"OPENAI_API_KEY\" : \"Put your key here in the quotes\",\n",
    "      \"base_url\" : \"https://api.ai.it.ufl.edu/\"\n",
    "    }\n",
    "\n",
    "We suggest putting that in your home directory, to minimize the chances of accidentally adding and committing the file to a git repo. Remember that anyone with your API key can use NaviGator as you! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ba376d4-d4f1-4e48-a7c0-3ca4a7c144c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0742a36-ccf5-4d0c-9c71-f2ba7b7735cb",
   "metadata": {},
   "source": [
    "## Load `.json` file with your key and api endpoint URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1742595-a563-4065-be5a-2b08107bdbe1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the path to your jsnkey file\n",
    "key_file = '/home/magitz/navigator_api_keys.json'\n",
    "\n",
    "\n",
    "# Load the JSON file\n",
    "with open(key_file, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract the values\n",
    "OPENAI_API_KEY = data.get('OPENAI_API_KEY')\n",
    "base_url = data.get('base_url')\n",
    "\n",
    "# Set the environment variable\n",
    "os.environ['TOOLKIT_API_KEY'] = OPENAI_API_KEY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05900196-4d7d-4dea-8b6a-9c119bfd3035",
   "metadata": {},
   "source": [
    "## Test connectivity and get model list\n",
    "\n",
    "Reply should list the models that are available with your API key. An example, truncated, output is:\n",
    "\n",
    "    SyncPage[Model](data=[Model(id='llama-3.1-70b-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='sfr-embedding-mistral', created=1677610602, object='model', owned_by='openai'),...)], object='list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ea3baa5-eea7-46f3-aa91-753907b44ad7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncPage[Model](data=[Model(id='flux.1-schnell', created=1677610602, object='model', owned_by='openai'), Model(id='granite-3.1-8b-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='llama-3.1-8b-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='mixtral-8x7b-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='nim-mistral-7b-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='llama-3.1-70b-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='nomic-embed-text-v1.5', created=1677610602, object='model', owned_by='openai'), Model(id='gte-large-en-v1.5', created=1677610602, object='model', owned_by='openai'), Model(id='mistral-7b-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='whisper-large-v3', created=1677610602, object='model', owned_by='openai'), Model(id='codestral-22b', created=1677610602, object='model', owned_by='openai'), Model(id='nim-llama-3.1-8b-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='flux.1-dev', created=1677610602, object='model', owned_by='openai'), Model(id='llama-3.3-70b-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='sfr-embedding-mistral', created=1677610602, object='model', owned_by='openai')], object='list')\n"
     ]
    }
   ],
   "source": [
    "# Check list of available models\n",
    "client = openai.OpenAI(\n",
    "    api_key=os.environ.get(\"TOOLKIT_API_KEY\"),\n",
    "    base_url=base_url\n",
    ")\n",
    "\n",
    "response = client.models.list()\n",
    " \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5718c829-bc94-454c-bbe8-1743465430c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flux.1-schnell\n",
      "granite-3.1-8b-instruct\n",
      "llama-3.1-8b-instruct\n",
      "mixtral-8x7b-instruct\n",
      "nim-mistral-7b-instruct\n",
      "llama-3.1-70b-instruct\n",
      "nomic-embed-text-v1.5\n",
      "gte-large-en-v1.5\n",
      "mistral-7b-instruct\n",
      "whisper-large-v3\n",
      "codestral-22b\n",
      "nim-llama-3.1-8b-instruct\n",
      "flux.1-dev\n",
      "llama-3.3-70b-instruct\n",
      "sfr-embedding-mistral\n"
     ]
    }
   ],
   "source": [
    "# Print available models in better format\n",
    "for model in response:\n",
    "    print(model.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f4cac6-0d83-4a2d-ae59-97c7dfba8a6e",
   "metadata": {},
   "source": [
    "## Test model completion\n",
    "\n",
    "You may need to update the model from the list above as the available models change over time.\n",
    "\n",
    "Here is an example response from the recording at `data/test_recording.m4a`:\n",
    "   \n",
    "    Transcription(text=\"This is a test audio recording. I want to test an AI model's ability to accurately generate a transcript of the recording. Thank you for listening, and go Gators!\", language='en', task='transcribe', duration=12.736, words=None, segments=[{'id': 1, 'avg_logprob': -0.07349917508269611, 'compression_ratio': 1.296, 'end': 11.52, 'no_speech_prob': 0.0149383544921875, 'seek': 1273, 'start': 0.0, 'temperature': 0.0, 'text': \" This is a test audio recording. I want to test an AI model's ability to accurately generate a transcript of the recording. Thank you for listening, and go Gators!\", 'tokens': [50365, 639, 307, 257, 1500, 6278, 6613, 13, 286, 528, 281, 1500, 364, 7318, 2316, 311, 3485, 281, 20095, 8460, 257, 24444, 295, 264, 6613, 13, 1044, 291, 337, 4764, 11, 293, 352, 460, 3391, 0, 50941], 'words': None}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc1c6dca-b4ed-4529-ae65-4f475fd18f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription(text=\"This is a test audio recording. I want to test an AI model's ability to accurately generate a transcript of the recording. Thank you for listening, and go Gators!\", language='en', task='transcribe', duration=12.736, words=None, segments=[{'id': 1, 'avg_logprob': -0.07349917508269611, 'compression_ratio': 1.296, 'end': 11.52, 'no_speech_prob': 0.0149383544921875, 'seek': 1273, 'start': 0.0, 'temperature': 0.0, 'text': \" This is a test audio recording. I want to test an AI model's ability to accurately generate a transcript of the recording. Thank you for listening, and go Gators!\", 'tokens': [50365, 639, 307, 257, 1500, 6278, 6613, 13, 286, 528, 281, 1500, 364, 7318, 2316, 311, 3485, 281, 20095, 8460, 257, 24444, 295, 264, 6613, 13, 1044, 291, 337, 4764, 11, 293, 352, 460, 3391, 0, 50941], 'words': None}])\n"
     ]
    }
   ],
   "source": [
    "# Set model from list above\n",
    "model = \"whisper-large-v3\"\n",
    "\n",
    "audio_file= open(\"data/test_recording.m4a\", \"rb\")\n",
    "transcription = client.audio.transcriptions.create(\n",
    "      model=\"whisper-large-v3\", \n",
    "      file=audio_file\n",
    "  )\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e759c8e-9de9-454a-b796-1d5240139d13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test audio recording. I want to test an AI model's ability to accurately generate a transcript of the recording. Thank you for listening, and go Gators!\n"
     ]
    }
   ],
   "source": [
    "# Print just the transcription text\n",
    "print(transcription.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-1.3",
   "language": "python",
   "name": "nlp-1.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
