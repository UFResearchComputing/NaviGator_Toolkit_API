{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b1c20c9-41b1-4b7c-98ee-cc38abcaf846",
   "metadata": {},
   "source": [
    "\n",
    "# NaviGator Toolkit API Model Eval Demo\n",
    "\n",
    "This notebook is designed to test connection to the NaviGator Toolkit API ([see here for more information](https://it.ufl.edu/ai/navigator-toolkit/)). You will need a NaviGator API key. The key should be stored in a `.json` file with the following format:\n",
    "\n",
    "    {\n",
    "      \"OPENAI_API_KEY\" : \"Put your key here in the quotes\",\n",
    "      \"base_url\" : \"https://api.ai.it.ufl.edu/\"\n",
    "    }\n",
    "\n",
    "We suggest putting that in your home directory, to minimize the chances of accidentally adding and committing the file to a git repo. Remember that anyone with your API key can use NaviGator as you! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca4deee2-254b-402f-b49b-5eb4dc519567",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1efadb7-59ba-45b9-aacb-76e90b79f5ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load `.json` file with your key and api endpoint URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b67400a1-d1f8-4435-865e-80d62e6e8cf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the path to your jsnkey file\n",
    "key_file = '/home/magitz/navigator_api_keys.json'\n",
    "\n",
    "\n",
    "# Load the JSON file\n",
    "with open(key_file, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract the values\n",
    "OPENAI_API_KEY = data.get('OPENAI_API_KEY')\n",
    "base_url = data.get('base_url')\n",
    "\n",
    "# Set the environment variable\n",
    "os.environ['TOOLKIT_API_KEY'] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b9e7e4-0d09-4732-9a60-8ea611fd44e1",
   "metadata": {},
   "source": [
    "## Test connectivity and get model list\n",
    "\n",
    "Reply should list the models that are available with your API key. An example, truncated, output is:\n",
    "\n",
    "    SyncPage[Model](data=[Model(id='llama-3.1-70b-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='sfr-embedding-mistral', created=1677610602, object='model', owned_by='openai'),...)], object='list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22645462-280c-4222-84ca-665d3f1d726a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncPage[Model](data=[Model(id='codestral-22b', created=1677610602, object='model', owned_by='openai'), Model(id='whisper-large-v3', created=1677610602, object='model', owned_by='openai'), Model(id='mistral-7b-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='mixtral-8x7b-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='gte-large-en-v1.5', created=1677610602, object='model', owned_by='openai'), Model(id='llama-3.1-8b-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='llama-3.1-70b-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='flux.1-dev', created=1677610602, object='model', owned_by='openai'), Model(id='flux.1-schnell', created=1677610602, object='model', owned_by='openai'), Model(id='sfr-embedding-mistral', created=1677610602, object='model', owned_by='openai'), Model(id='nomic-embed-text-v1.5', created=1677610602, object='model', owned_by='openai')], object='list')\n"
     ]
    }
   ],
   "source": [
    "# Check list of available models\n",
    "client = openai.OpenAI(\n",
    "    api_key=os.environ.get(\"TOOLKIT_API_KEY\"),\n",
    "    base_url=base_url\n",
    ")\n",
    "\n",
    "response = client.models.list()\n",
    " \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2919575-f121-4a7e-a397-11e9fc440047",
   "metadata": {},
   "source": [
    "## Parse list of available models, keep only the models you want to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f04128a-f28f-4d61-a5a4-d7da36e521f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making a list of available models:\n",
      "Model name: codestral-22b\n",
      "Model name: whisper-large-v3\n",
      "Model name: mistral-7b-instruct\n",
      "Model name: mixtral-8x7b-instruct\n",
      "Model name: gte-large-en-v1.5\n",
      "Model name: llama-3.1-8b-instruct\n",
      "Model name: llama-3.1-70b-instruct\n",
      "Model name: flux.1-dev\n",
      "Model name: flux.1-schnell\n",
      "Model name: sfr-embedding-mistral\n",
      "Model name: nomic-embed-text-v1.5\n",
      "Your API key has access to 11 models, of those 5 are in your list of 5 models to test.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Not all models in NaviGator are LLMs\n",
    "models_to_test=['codestral-22b',\n",
    " 'mistral-7b-instruct',\n",
    " 'mixtral-8x7b-instruct',\n",
    " 'llama-3.1-8b-instruct',\n",
    " 'llama-3.1-70b-instruct']\n",
    "\n",
    "\n",
    "print(\"Making a list of available models:\")\n",
    "model_list=[]\n",
    "for model in response.data:\n",
    "    print(f'Model name: {model.id}')\n",
    "    if model.id in models_to_test:\n",
    "        model_list.append(model.id)\n",
    "    \n",
    "print(f'Your API key has access to {len(response.data)} models, of those {len(model_list)} are in your list of {len(models_to_test)} models to test.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1fa0ade-4f52-4bdc-b701-446bb361e14c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['codestral-22b',\n",
       " 'mistral-7b-instruct',\n",
       " 'mixtral-8x7b-instruct',\n",
       " 'llama-3.1-8b-instruct',\n",
       " 'llama-3.1-70b-instruct']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f854f846-91e3-4b6e-a2b5-fbc0151b24ff",
   "metadata": {},
   "source": [
    "## Create sample query to pass to all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9cab9fa8-683b-42ae-a81e-968284ceb5db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '''Please write a Python function that reads in data from the file demo.csv. \n",
    "           The file has the following columns: Age, Test_score, Hours_studied, Course_load,\n",
    "           and 1/0 if a student passes the final exam. Please make a Logistic model to predict\n",
    "           is a student passes the exam based on the other data. Please use 5-fold cross-validation.\n",
    "           Plot a confusion matrix, and other measures to evaluate the performance of the model. \n",
    "           Comment all code with explanations and possible parameter adjustment to improve the model.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c403b37-a71a-4281-ab7e-c3482e9b60da",
   "metadata": {},
   "source": [
    "## Send the query to the models and save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4991b78-1fba-4f7c-a4dd-c18c8e38614c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending the following query to each model in the list: \n",
      " Please write a Python function that reads in data from the file demo.csv. \n",
      "           The file has the following columns: Age, Test_score, Hours_studied, Course_load,\n",
      "           and 1/0 if a student passes the final exam. Please make a Logistic model to predict\n",
      "           is a student passes the exam based on the other data. Please use 5-fold cross-validation.\n",
      "           Plot a confusion matrix, and other measures to evaluate the performance of the model. \n",
      "           Comment all code with explanations and possible parameter adjustment to improve the model.\n",
      "Sending query to codestral-22b\n",
      "Sending query to mistral-7b-instruct\n",
      "Sending query to mixtral-8x7b-instruct\n",
      "Sending query to llama-3.1-8b-instruct\n",
      "Sending query to llama-3.1-70b-instruct\n",
      "Queries finished.\n"
     ]
    }
   ],
   "source": [
    "out_file_base = 'code_' # prefix for the output file, will have model name added\n",
    "\n",
    "print(f'Sending the following query to each model in the list: \\n {query}')\n",
    "\n",
    "for model in model_list:\n",
    "    print(f'Sending query to {model}')\n",
    "    response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages = [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": query\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "    # Write reponse to file    \n",
    "    try:\n",
    "        out_file = out_file_base + model + '.md'\n",
    "        with open(out_file, 'w') as f:\n",
    "            f.write(response.choices[0].message.content)\n",
    "        f.close()\n",
    "    except Exception as e:\n",
    "        print('Error writing file.', e)\n",
    "print('Queries finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119ae82a-6a05-45dd-8bd0-e6ff96de6b08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-1.3",
   "language": "python",
   "name": "nlp-1.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
